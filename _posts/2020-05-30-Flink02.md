Flink Data Stream API

工业物联网例子贯穿起来，传感器读数的数据流。

### 如何自定义数据源 ？

```scala
//样例类
case class SensorReading(id:String,timestamp:Long,temperature:Double)

//继承RichParallelSourceFunction类泛型是[SensorReading]
class SensorSource extends RichParallelSourceFunction[SensorReading]{
  //定义一个变量做flag用
  var running =true
  //重写run方法
  override def run(sourceContext: SourceContext[SensorReading]):
  Unit = {
    //初始化随机发生器
    val rand = new Random()
    //初始化10个温度传感器
    var curFTemp = (1 to 10).map{
      i => ("sensor_"+i,65 + (rand.nextGaussian()*20))
    }
    //无限循环，产生数据流
    while(running){
      //更新温度
      curFTemp = curFTemp.map(t=>(t._1,t._2 + (rand.nextGaussian()*0.5)))
      //获取当前时间戳
      val curTime = Calendar.getInstance().getTimeInMillis

      //发射新的传感器数据，注意sourceContext.collect的使用
      curFTemp.foreach(t=>
      sourceContext.collect(SensorReading(t._1,curTime,t._2)))

      //等待100ms
      Thread.sleep(100)
    }
  }

  //override cancel 函数
  override def cancel(): Unit = {
    running = false
  }
}
```

------

### 使用数据源

```scala
def main(args: Array[String]): Unit = {
    //1.运行环境
  val env = StreamExecutionEnvironment.getExecutionEnvironment
    //2.设置并行度
  env.setParallelism(1)
    //3.获取数据源
  val stream = env.addSource(new SensorSource)
    //4.使用数据源
  stream.print()
    //5.执行
  env.execute()
  }
```

------

### 转换算子

转换算子的时候底层都是UDF函数

* 基本转换算子：将会作用在数据流中的每一条单独的数据上。
* KeyedStream转换算子：在数据有key的情况下，对数据应用转换算子。
* 多流转换算子：合并多条流为一条流或者将一条流分割为多条流。
* 分布式转换算子：将重新组织流里面的事件。

#### 基本转换算子

MAP算子 [一对一]

```scala
// T: 输入类型
// O: 输出类型
MapFunction[T, O]
    > map(T): O//需要重写的函数
```

FILTER算子 [不改变输入流类型，过滤]

```java
// T: the type of elements
FilterFunction[T]//需要继承的类和他的泛型
    > filter(T): Boolean//需要重写的函数
```

FLATMAP算子---最精髓的算子，可以实现MAP和FILTER的功能,**集合**

```scala
//来一条元素可以生成0条一条或者多条数据
// T: 输入类型
// O: 输出类型
FlatMapFunction[T, O]
    > flatMap(T, Collector[O]): Unit
```

```scala
//输入1L啥也不做
//输入2L输出一次
//输入3L输出两次
package com.atguigu.datastreamapi
import org.apache.flink.api.common.functions.FlatMapFunction
import org.apache.flink.streaming.api.scala._
import org.apache.flink.util.Collector

object FlatMapExample {
  def main(args: Array[String]): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    env.setParallelism(1)
    val stream = env
      .addSource(new SensorSource)
        .fromElements(
          1L, 2L, 3L
        )
        .flatMap(new MyFlatMapFunction)

    stream.print()
    
    env.execute()

  }

  class MyFlatMapFunction extends FlatMapFunction[Long, Long] {
    override def flatMap(value: Long, out: Collector[Long]): Unit = {
      if (value == 2) {
        out.collect(value)
      } else if (value == 3) {
        out.collect(value)
        out.collect(value)
      }
    }
  }
}
```

匿名函数

UDF函数

匿名类

#### KeyedStream转换算子[键控流の转换算子]

保存了状态的

**基本转换算子**对流转换以后流的类型`不发生改变`

**KeyedStream转换算子**对流转换以后流的类型`发生改变 ` DataStream => KeyedStream => DataStream

KEYBY算子

滚动聚合不需要自定义函数，需要一个参数，不能用在滑动窗口

* sum()：在输入流上对指定的字段做滚动相加操作。
* min()：在输入流上对指定的字段求最小值。
* max()：在输入流上对指定的字段求最大值。
* minBy()：在输入流上针对指定字段求最小值，并返回包含当前观察到的最小值的事件。
* maxBy()：在输入流上针对指定字段求最大值，并返回包含当前观察到的最大值的事件。

滚动聚合不支持链式调用，滚动聚合算子无法组合起来使用，每次计算只能使用一个单独的滚动聚合算子。

REDUCE算子

reduce算子是滚动聚合的泛化实现。

```scala
// T: 事件类型
ReduceFunction[T]
    >reduce(T, T): T//接收两个类型相同的事件，输出一个
```

#### 多流转换算子

多流合并或者一条流切分成多条流

UNION算子

合并流的，可以合并N条流，事件类型相同

CONNECT算子

key一样的会被分发到同一个并行任务

```scala
// IN1: 第一条流的事件类型
// IN2: 第二条流的事件类型
// OUT: 输出流的事件类型
CoMapFunction[IN1, IN2, OUT]
    > map1(IN1): OUT//处理来自第一条流的事件，函数没有办法选择读那条流
    > map2(IN2): OUT
```

只能把两条流联合起来产生ConnectedStream，key相同就行

COMAP算子

COFLATMAP

```scala
// IN1: 第一条流的事件类型
// IN2: 第二条流的事件类型
// OUT: 输出流的事件类型
CoFlatMapFunction[IN1, IN2, OUT]
    > flatMap1(IN1, Collector[OUT]): Unit
    > flatMap2(IN2, Collector[OUT]): Unit
```

#### 分布式转换算子

### UDF函数

### 窗口操作

#### 窗口增量聚合

#### 全窗口聚合

#### 增量聚合和全窗口聚合联合使用